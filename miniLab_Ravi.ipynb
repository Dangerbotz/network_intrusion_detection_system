{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82332 entries, 0 to 82331\n",
      "Data columns (total 6 columns):\n",
      "sttl                82332 non-null int64\n",
      "ct_dst_sport_ltm    82332 non-null int64\n",
      "ct_src_dport_ltm    82332 non-null int64\n",
      "swin                82332 non-null int64\n",
      "dwin                82332 non-null int64\n",
      "label               82332 non-null int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "df = pd.read_csv('miniLab.csv') # read in the csv file\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sttl</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>180.967667</td>\n",
       "      <td>101.513358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std  min   25%    50%    75%    max\n",
       "label  82332.0    0.550600    0.497436  0.0   0.0    1.0    1.0    1.0\n",
       "sttl   82332.0  180.967667  101.513358  0.0  62.0  254.0  254.0  255.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: calling describe when not all the data is categorical will cause the \n",
    "# categorical variables to be removed\n",
    "df[['label','sttl']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>3.663011</td>\n",
       "      <td>5.915386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count      mean       std  min  25%  50%  75%   max\n",
       "label             82332.0  0.550600  0.497436  0.0  0.0  1.0  1.0   1.0\n",
       "ct_dst_sport_ltm  82332.0  3.663011  5.915386  1.0  1.0  1.0  3.0  38.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: calling describe when not all the data is categorical will cause the \n",
    "# categorical variables to be removed\n",
    "df[['label','ct_dst_sport_ltm']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>4.928898</td>\n",
       "      <td>8.389545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count      mean       std  min  25%  50%  75%   max\n",
       "label             82332.0  0.550600  0.497436  0.0  0.0  1.0  1.0   1.0\n",
       "ct_src_dport_ltm  82332.0  4.928898  8.389545  1.0  1.0  1.0  4.0  59.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['label','ct_src_dport_ltm']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>0.55060</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>133.45908</td>\n",
       "      <td>127.357000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count       mean         std  min  25%    50%    75%    max\n",
       "label  82332.0    0.55060    0.497436  0.0  0.0    1.0    1.0    1.0\n",
       "swin   82332.0  133.45908  127.357000  0.0  0.0  255.0  255.0  255.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['label','swin']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>0.55060</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwin</th>\n",
       "      <td>82332.0</td>\n",
       "      <td>128.28662</td>\n",
       "      <td>127.491370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count       mean         std  min  25%    50%    75%    max\n",
       "label  82332.0    0.55060    0.497436  0.0  0.0    1.0    1.0    1.0\n",
       "dwin   82332.0  128.28662  127.491370  0.0  0.0  255.0  255.0  255.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['label','dwin']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(82332, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'label' in df:\n",
    "    y = df['label'].values # get the labels we want\n",
    "    del df['label'] # get rid of the class label\n",
    "    X = df.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.766806339953\n",
      "confusion matrix\n",
      " [[4888 2498]\n",
      " [1342 7739]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.767292160078\n",
      "confusion matrix\n",
      " [[4960 2490]\n",
      " [1342 7675]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.76419505678\n",
      "confusion matrix\n",
      " [[4860 2505]\n",
      " [1378 7724]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "    \n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.767595797656\n",
      "confusion matrix\n",
      " [[4969 2498]\n",
      " [1329 7671]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.768810347969\n",
      "confusion matrix\n",
      " [[4959 2446]\n",
      " [1361 7701]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.767352887593\n",
      "confusion matrix\n",
      " [[4884 2513]\n",
      " [1318 7752]]\n"
     ]
    }
   ],
   "source": [
    "# this does the exact same thing as the above block of code, but with shorter syntax\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object):\n",
    "    lr_clf.fit(X[train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict(X[test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76267687  0.76747434  0.76589543]\n"
     ]
    }
   ],
   "source": [
    "# and here is an even shorter way of getting the accuracies for each training and test set\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76838526  0.76121941  0.76911399]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lr_explor>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we can change some of the parameters interactively\n",
    "from ipywidgets import widgets as wd\n",
    "\n",
    "def lr_explor(cost):\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=cost, class_weight=None) # get object\n",
    "    accuracies = cross_val_score(lr_clf,X,y=y,cv=cv_object) # this also can help with parallelism\n",
    "    print(accuracies)\n",
    "\n",
    "wd.interact(lr_explor,cost=(0.001,5.0,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sttl has weight of 0.0080323486967\n",
      "ct_dst_sport_ltm has weight of 1.32480623373\n",
      "ct_src_dport_ltm has weight of -0.212352534678\n",
      "swin has weight of -0.026754227668\n",
      "dwin has weight of 0.0258834959026\n"
     ]
    }
   ],
   "source": [
    "# interpret the weights\n",
    "\n",
    "# iterate over the coefficients\n",
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = df.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "    \n",
    "# does this look correct? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.764255784296\n",
      "[[4850 2515]\n",
      " [1367 7735]]\n",
      "sttl has weight of 0.823093393799\n",
      "ct_src_dport_ltm has weight of -1.38813676716\n",
      "dwin has weight of 1.97811317554\n",
      "swin has weight of -2.1366175104\n",
      "ct_dst_sport_ltm has weight of 5.99660826688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,df.columns) # combine attributes\n",
    "zip_vars.sort(key = lambda t: np.abs(t[0])) # sort them by the magnitude of the weight\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAFMCAYAAAA5llzqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAagzAHAAP8HLvq2HAM7O+AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8928a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAFMCAYAAAA5llzqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb206a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can also apply the StandardScaler function insied of the validation loop \n",
    "#  but this requires the use of PipeLines in scikit. Here is an example, but we will go over more \n",
    "#  thorough examples later in class\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) \n",
    "\n",
    "# create the pipline\n",
    "piped_object = Pipeline([('scale', std_scl), ('logit_model', lr_clf)])\n",
    "\n",
    "# run the pipline corssvalidated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object):\n",
    "    piped_object.fit(X[train_indices],y[train_indices])  # train object\n",
    "    \n",
    "# it is a little odd getting trained objects from a  pipeline:\n",
    "trained_model_from_pipeline = piped_object.named_steps['logit_model']\n",
    "\n",
    "# now look at the weights\n",
    "weights = pd.Series(trained_model_from_pipeline.coef_[0],index=df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
