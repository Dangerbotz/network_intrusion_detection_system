{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Conventions\n",
    "<code>\n",
    "df_final = final dataframe\n",
    "df = original dataframe\n",
    "df_five = 5 variables # Use as default unless Peter's analysis suggest otherwise\n",
    "df_seven = 7 variables\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.decomposition import RandomizedPCA \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82328 entries, 0 to 82331\n",
      "Data columns (total 6 columns):\n",
      "sttl                82328 non-null int64\n",
      "ct_dst_sport_ltm    82328 non-null int64\n",
      "ct_src_dport_ltm    82328 non-null int64\n",
      "swin                82328 non-null int64\n",
      "dwin                82328 non-null int64\n",
      "label               82328 non-null int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 4.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sttl</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>swin</th>\n",
       "      <th>dwin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180.973448</td>\n",
       "      <td>3.663092</td>\n",
       "      <td>4.929040</td>\n",
       "      <td>133.453175</td>\n",
       "      <td>128.280464</td>\n",
       "      <td>0.550578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.512436</td>\n",
       "      <td>5.915518</td>\n",
       "      <td>8.389724</td>\n",
       "      <td>127.357276</td>\n",
       "      <td>127.491408</td>\n",
       "      <td>0.497438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sttl  ct_dst_sport_ltm  ct_src_dport_ltm          swin  \\\n",
       "count  82328.000000      82328.000000      82328.000000  82328.000000   \n",
       "mean     180.973448          3.663092          4.929040    133.453175   \n",
       "std      101.512436          5.915518          8.389724    127.357276   \n",
       "min        0.000000          1.000000          1.000000      0.000000   \n",
       "25%       62.000000          1.000000          1.000000      0.000000   \n",
       "50%      254.000000          1.000000          1.000000    255.000000   \n",
       "75%      254.000000          3.000000          4.000000    255.000000   \n",
       "max      255.000000         38.000000         59.000000    255.000000   \n",
       "\n",
       "               dwin         label  \n",
       "count  82328.000000  82328.000000  \n",
       "mean     128.280464      0.550578  \n",
       "std      127.491408      0.497438  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%      255.000000      1.000000  \n",
       "75%      255.000000      1.000000  \n",
       "max      255.000000      1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load UNSW_NB15 into a Pandas dataframe\n",
    "df = pd.read_csv('UNSW_NB15_training_set.csv')\n",
    "\n",
    "\n",
    "# Remove the four duplicate rows with invalid value for is_ftp_login\n",
    "df = df[df.is_ftp_login != 2]\n",
    "\n",
    "# original df_five from minilab that were selected based off results from correlation matrix as most important features.\n",
    "df_five = df[['sttl','ct_dst_sport_ltm', 'ct_src_dport_ltm', 'swin', 'dwin', 'label' ]] # \n",
    "df_five.info()\n",
    "df_five.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82328 entries, 0 to 82331\n",
      "Data columns (total 8 columns):\n",
      "sttl                82328 non-null int64\n",
      "ct_dst_sport_ltm    82328 non-null int64\n",
      "ct_src_dport_ltm    82328 non-null int64\n",
      "swin                82328 non-null int64\n",
      "dwin                82328 non-null int64\n",
      "dttl                82328 non-null int64\n",
      "ct_dst_src_ltm      82328 non-null int64\n",
      "label               82328 non-null int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 5.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sttl</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>swin</th>\n",
       "      <th>dwin</th>\n",
       "      <th>dttl</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.00000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180.973448</td>\n",
       "      <td>3.663092</td>\n",
       "      <td>4.929040</td>\n",
       "      <td>133.453175</td>\n",
       "      <td>128.280464</td>\n",
       "      <td>95.70541</td>\n",
       "      <td>7.456528</td>\n",
       "      <td>0.550578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.512436</td>\n",
       "      <td>5.915518</td>\n",
       "      <td>8.389724</td>\n",
       "      <td>127.357276</td>\n",
       "      <td>127.491408</td>\n",
       "      <td>116.66547</td>\n",
       "      <td>11.415443</td>\n",
       "      <td>0.497438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>252.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sttl  ct_dst_sport_ltm  ct_src_dport_ltm          swin  \\\n",
       "count  82328.000000      82328.000000      82328.000000  82328.000000   \n",
       "mean     180.973448          3.663092          4.929040    133.453175   \n",
       "std      101.512436          5.915518          8.389724    127.357276   \n",
       "min        0.000000          1.000000          1.000000      0.000000   \n",
       "25%       62.000000          1.000000          1.000000      0.000000   \n",
       "50%      254.000000          1.000000          1.000000    255.000000   \n",
       "75%      254.000000          3.000000          4.000000    255.000000   \n",
       "max      255.000000         38.000000         59.000000    255.000000   \n",
       "\n",
       "               dwin         dttl  ct_dst_src_ltm         label  \n",
       "count  82328.000000  82328.00000    82328.000000  82328.000000  \n",
       "mean     128.280464     95.70541        7.456528      0.550578  \n",
       "std      127.491408    116.66547       11.415443      0.497438  \n",
       "min        0.000000      0.00000        1.000000      0.000000  \n",
       "25%        0.000000      0.00000        1.000000      0.000000  \n",
       "50%      255.000000     29.00000        3.000000      1.000000  \n",
       "75%      255.000000    252.00000        6.000000      1.000000  \n",
       "max      255.000000    253.00000       63.000000      1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on feedback fro mini lab Check if accuracy increases from the selected 5 features to include the following\n",
    "# two additional features: 'dttl', 'ct_dst_src_ltm',\n",
    "df_seven = df[['sttl','ct_dst_sport_ltm', 'ct_src_dport_ltm', 'swin', 'dwin', 'dttl', 'ct_dst_src_ltm', 'label' ]] # \n",
    "df_seven.info()\n",
    "df_seven.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:\n",
    "\n",
    "* Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peter\n",
    "# df_five and df_seven based of describe does not require one-hot encoding and is ready for modeling\n",
    "# First lets redo accuracy results for logistic regression on original 5 features selected based on correlation matrix from\n",
    "# from lab 1 for accuracy comparision with additional 2 features suggested by grader using logistic regression model\n",
    "# with 80/20 shuffle split cross validation to determine if we should proceed with original 5 or add additional two features for\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(82328, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# we want to predict the X and y data as follows for 5 feature iteration: \n",
    "if 'label' in df_five:\n",
    "    y = df_five['label'].values # get the labels we want\n",
    "    del df_five['label'] # get rid of the class label\n",
    "    X = df_five.values # use everything else to predict!\n",
    "\n",
    "    # X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    # have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print cv_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76588121  0.76928216  0.76612413]\n",
      "Average Accuracy (5 feature set) across 3 shuffle split cross validation iterations = 0.767095833839\n"
     ]
    }
   ],
   "source": [
    "# first we create a reusable logisitic regression object\n",
    "# here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "for train_indices, test_indices in cv_object:\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)\n",
    "print \"Average Accuracy (5 feature set) across \" + str(num_cv_iterations) + \" shuffle split cross validation iterations = \" + str(np.average(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(82328, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# we want to predict the X and y data as follows for 7 feature iteration: \n",
    "if 'label' in df_seven:\n",
    "    y = df_seven['label'].values # get the labels we want\n",
    "    del df_seven['label'] # get rid of the class label\n",
    "    X = df_seven.values # use everything else to predict!\n",
    "\n",
    "    # X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    # have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print cv_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77280457  0.77043605  0.77620551]\n",
      "Average Accuracy (7 feature set) across 3 shuffle split cross validation iterations = 0.773148710474\n"
     ]
    }
   ],
   "source": [
    "# first we create a reusable logisitic regression object\n",
    "# here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "for train_indices, test_indices in cv_object:\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)\n",
    "print \"Average Accuracy (7 feature set) across \" + str(num_cv_iterations) + \" shuffle split cross validation iterations = \" + str(np.average(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results there was negligible increase in accuracy with respect to including the additional 2 features\n",
    "requested by the grader in terms of explaining the data.  Hence we we stick with the original 5 based on correlation results\n",
    "from mini lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation:\n",
    "* Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "\n",
    "http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/\n",
    "\n",
    "Once you have a model that you believe can make robust predictions you need to decide whether it is a good enough model to solve your problem. Classification accuracy alone is typically not enough information to make this decision.\n",
    "\n",
    "Classification accuracy is our starting point. It is the number of correct predictions made divided by the total number of predictions made, multiplied by 100 to turn it into a percentage.\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "\n",
    "In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n",
    "\n",
    "A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly.\n",
    "\n",
    "Precision (P) is defined as the number of true positives (T_p) over the number of true positives plus the number of false positives (F_p).\n",
    "\n",
    "P = T_p / (T_p+F_p)\n",
    "\n",
    "Recall (R) is defined as the number of true positives (T_p) over the number of true positives plus the number of false negatives (F_n).\n",
    "\n",
    "R = (T_p) / (T_p + F_n)\n",
    "\n",
    "These quantities are also related to the (F_1) score, which is defined as the harmonic mean of precision and recall.\n",
    "\n",
    "F1 = 2 ( (P*R) / (P+R) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ravi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peter, Ravi, Randy, and Daniel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team or TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team or TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment:\n",
    "* How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Daniel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work:\n",
    "\n",
    "You have free reign to provide additional analyses\n",
    "\n",
    "• One idea: grid search parameters in a parallelized fashion and visualize the\n",
    "performances across attributes. Which parameters are most significant for making a\n",
    "good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randy and team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
