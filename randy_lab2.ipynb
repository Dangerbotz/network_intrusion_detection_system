{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.decomposition import RandomizedPCA \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:\n",
    "\n",
    "* Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate record deleted successfully: 82328 observations remaining\n"
     ]
    }
   ],
   "source": [
    "# Load UNSW_NB15 into a Pandas dataframe\n",
    "df = pd.read_csv('UNSW_NB15_training_set.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Lets remove attributes that are not useful to us during this first analysis pass\n",
    "non_useful_features_list = ['id', 'attack_cat']\n",
    "# id: n internal variable to just ref an obseration. deemed not usefl\n",
    "# attack_cat: first try and just predict the label. \n",
    "#             It will obviously 1:1 correlate with label\n",
    "#             We can circle back and swap it out with label \n",
    "#             to see if we get any better accuracy on an \n",
    "#             on an attack type level\n",
    "for feature in non_useful_features_list:\n",
    "    if feature in df:\n",
    "        df.drop(feature, axis=1, inplace=True)  # Lets drop id as it is an internal variable to just ref an obseratio\n",
    "        \n",
    "# Overwrite the existing dataframe with the new dataframe that does not contain the \n",
    "# four unwanted records and confirm we have 4 less records (shold have 82328 observations)\n",
    "if \"is_ftp_login\" in df:\n",
    "    df = df[df.is_ftp_login != 2]\n",
    "    if len(df) == 82328:\n",
    "        print (\"duplicate record deleted successfully: \" + str(len(df)) + \" observations remaining\" )\n",
    "        \n",
    "# Check to see if non useful features still exist in dataframe, if so, we did something wrong\n",
    "for feature in non_useful_features_list:\n",
    "    if feature in df:\n",
    "        print (\"[\" + feature + \"]\" + \"still found, check removal code. (Should not see this)\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>8.232800e+04</td>\n",
       "      <td>8.232800e+04</td>\n",
       "      <td>8.232800e+04</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.00000</td>\n",
       "      <td>8.232800e+04</td>\n",
       "      <td>8.232800e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.006783</td>\n",
       "      <td>18.666893</td>\n",
       "      <td>17.546303</td>\n",
       "      <td>7.994267e+03</td>\n",
       "      <td>1.323440e+04</td>\n",
       "      <td>8.241489e+04</td>\n",
       "      <td>180.973448</td>\n",
       "      <td>95.70541</td>\n",
       "      <td>6.455215e+07</td>\n",
       "      <td>6.305771e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.929040</td>\n",
       "      <td>3.663092</td>\n",
       "      <td>7.456528</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.129749</td>\n",
       "      <td>6.468480</td>\n",
       "      <td>9.164610</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.550578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.710557</td>\n",
       "      <td>133.919593</td>\n",
       "      <td>115.576881</td>\n",
       "      <td>1.716464e+05</td>\n",
       "      <td>1.514751e+05</td>\n",
       "      <td>1.486229e+05</td>\n",
       "      <td>101.512436</td>\n",
       "      <td>116.66547</td>\n",
       "      <td>1.798656e+08</td>\n",
       "      <td>2.393055e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.389724</td>\n",
       "      <td>5.915518</td>\n",
       "      <td>11.415443</td>\n",
       "      <td>0.090110</td>\n",
       "      <td>0.091439</td>\n",
       "      <td>0.638697</td>\n",
       "      <td>8.544117</td>\n",
       "      <td>11.121571</td>\n",
       "      <td>0.104893</td>\n",
       "      <td>0.497438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.860585e+01</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.120356e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.014120</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.340000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>2.651198e+03</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>5.770751e+05</td>\n",
       "      <td>2.112632e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.719362</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.280000e+03</td>\n",
       "      <td>9.560000e+02</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.00000</td>\n",
       "      <td>6.514286e+07</td>\n",
       "      <td>1.585818e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.999989</td>\n",
       "      <td>10646.000000</td>\n",
       "      <td>11018.000000</td>\n",
       "      <td>1.435577e+07</td>\n",
       "      <td>1.465753e+07</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>5.268000e+09</td>\n",
       "      <td>2.082111e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dur         spkts         dpkts        sbytes        dbytes  \\\n",
       "count  82328.000000  82328.000000  82328.000000  8.232800e+04  8.232800e+04   \n",
       "mean       1.006783     18.666893     17.546303  7.994267e+03  1.323440e+04   \n",
       "std        4.710557    133.919593    115.576881  1.716464e+05  1.514751e+05   \n",
       "min        0.000000      1.000000      0.000000  2.400000e+01  0.000000e+00   \n",
       "25%        0.000008      2.000000      0.000000  1.140000e+02  0.000000e+00   \n",
       "50%        0.014120      6.000000      2.000000  5.340000e+02  1.780000e+02   \n",
       "75%        0.719362     12.000000     10.000000  1.280000e+03  9.560000e+02   \n",
       "max       59.999989  10646.000000  11018.000000  1.435577e+07  1.465753e+07   \n",
       "\n",
       "               rate          sttl         dttl         sload         dload  \\\n",
       "count  8.232800e+04  82328.000000  82328.00000  8.232800e+04  8.232800e+04   \n",
       "mean   8.241489e+04    180.973448     95.70541  6.455215e+07  6.305771e+05   \n",
       "std    1.486229e+05    101.512436    116.66547  1.798656e+08  2.393055e+06   \n",
       "min    0.000000e+00      0.000000      0.00000  0.000000e+00  0.000000e+00   \n",
       "25%    2.860585e+01     62.000000      0.00000  1.120356e+04  0.000000e+00   \n",
       "50%    2.651198e+03    254.000000     29.00000  5.770751e+05  2.112632e+03   \n",
       "75%    1.111111e+05    254.000000    252.00000  6.514286e+07  1.585818e+04   \n",
       "max    1.000000e+06    255.000000    253.00000  5.268000e+09  2.082111e+07   \n",
       "\n",
       "           ...       ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "count      ...           82328.000000      82328.000000    82328.000000   \n",
       "mean       ...               4.929040          3.663092        7.456528   \n",
       "std        ...               8.389724          5.915518       11.415443   \n",
       "min        ...               1.000000          1.000000        1.000000   \n",
       "25%        ...               1.000000          1.000000        1.000000   \n",
       "50%        ...               1.000000          1.000000        3.000000   \n",
       "75%        ...               4.000000          3.000000        6.000000   \n",
       "max        ...              59.000000         38.000000       63.000000   \n",
       "\n",
       "       is_ftp_login    ct_ftp_cmd  ct_flw_http_mthd    ct_src_ltm  \\\n",
       "count  82328.000000  82328.000000      82328.000000  82328.000000   \n",
       "mean       0.008187      0.008284          0.129749      6.468480   \n",
       "std        0.090110      0.091439          0.638697      8.544117   \n",
       "min        0.000000      0.000000          0.000000      1.000000   \n",
       "25%        0.000000      0.000000          0.000000      1.000000   \n",
       "50%        0.000000      0.000000          0.000000      3.000000   \n",
       "75%        0.000000      0.000000          0.000000      7.000000   \n",
       "max        1.000000      2.000000         16.000000     60.000000   \n",
       "\n",
       "         ct_srv_dst  is_sm_ips_ports         label  \n",
       "count  82328.000000     82328.000000  82328.000000  \n",
       "mean       9.164610         0.011126      0.550578  \n",
       "std       11.121571         0.104893      0.497438  \n",
       "min        1.000000         0.000000      0.000000  \n",
       "25%        2.000000         0.000000      0.000000  \n",
       "50%        5.000000         0.000000      1.000000  \n",
       "75%       11.000000         0.000000      1.000000  \n",
       "max       62.000000         1.000000      1.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation:\n",
    "* Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769480519481\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = df.values\n",
    "\n",
    "X = array[:,0:41]\n",
    "Y = array[:,41]\n",
    "\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold)\n",
    "#print( str(results.mean()) )\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment:\n",
    "* How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance ratio (first component): 80.63\n",
      "explained variance ratio (first two components): [ 80.62648708  18.61891863]\n",
      "explained variance ratio (first three components): [ 80.62648708  18.61891863   0.75445077]\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.select_dtypes(['float64', 'int64'])\n",
    "\n",
    "y = df.attack_cat\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Percentage of variance explained by first component\n",
    "#######################################################\n",
    "pca = PCA(n_components=1)\n",
    "x_pca = pca.fit(df_copy).transform(df_copy)\n",
    "\n",
    "# Percentage of variance explained for each component\n",
    "print('explained variance ratio (first component): %3.2f'\n",
    "      % (100 * pca.explained_variance_ratio_))\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Percentage of variance explained for first two components\n",
    "############################################################\n",
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit(df_copy).transform(df_copy)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % (100 * pca.explained_variance_ratio_) )\n",
    "\n",
    " \n",
    "##############################################################\n",
    "# Percentage of variance explained for first three components\n",
    "##############################################################\n",
    "pca = PCA(n_components=3)\n",
    "x_pca = pca.fit(df_copy).transform(df_copy) \n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first three components): %s'\n",
    "      % (100 * pca.explained_variance_ratio_) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
